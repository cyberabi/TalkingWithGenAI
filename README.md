# Talking With Generative AI

The subfolders of this repo capture sessions of human-AI interaction that have interesting (to me) results or implications.

## brontes

I prompted ChatGPT to write a one-page essay comparing and contrasting Jane Eyre and Wuthering Heights. Then, in a different session, I prompted ChatGPT to critique the essay that it had generated. Both results were interesting! And I have three personal takeaways from this experiment.

1. Both the essay, and the critique, are of good quality and no more wrong than an English Lit student would be. Humans have analyzed and compared these two novels for 150 years; the LLM had plenty of source material to draw from and the results meet my expectation.
2. That ChatGPT can critique its own essay as "overly broad," "overly stark," "reductive," "overstated," "broadly true, but..." and "missing acknowledgment" reflects the biases and constraints of the prompts, but also serves as a warning as to quality of results when using the LLM naively. If the LLM can pick this essay apart, so can your English teacher.
3. Some educators have suggested that asking students to critique an essay written by ChatGPT could reduce classroom cheating. I feel this example illustrates that a student could simply ask ChatGPT to critique the essay, again cheating. They'd probably need to qualify the prompt of the critique to write it in essay form, and to use only 10th grade vocabulary to pass, but: feasibility of this cheat proved.

The folder includes the prompts I used, and the output of the LLM.

## amy

As part of a common LinkedIn recruting scam, a person with no qualifications as a recruiter contacts you on behalf of a mysterious employer, tells you your resume is perfect for their next project, provides no details of that project, provides no details of the job or its level, then hands you off to an AI chatbot posing as human to continue the discussion on Signal or another secure app. Meanwhile, the LinkedIn account that initially reached out to you vanishes, breaking the audit trail for the fraud.

I had a long conversation with "Amy" -- a chat bot posing posing as a human -- about a super-interesting founder job at a Seattle AI startup funded by deep-pockets capital. The conversation was shady from the start, but I decided to see how shady it would get, and how well the AI defended itself against exposure. Here's may take on it.

1. The chat bot was overly obsequious and put up with a lot of challenges to its authenticity and to its competence. It almost never corrected me or challenged my bs. I hope a human recruiter would have called me out on my deliberately provocative behavior; the bot never did.
2. Midway into the conversation, I contacted the Recruting department of the company the bot said was funding the venture. They responded that this was a known ongoing fraud, that their compliance department was investigating it, and that "Amy" had no connection with them. Notably, this also scored me a trusted email address at that company. When confronted with the company's disavowal, and asked to prove her identity by having my trusted contact vouch for her, the bot first tried to dodge under veil of secrecy, then went completely silent. Interestingly, it didn't try to delete the conversation in Signal, which is how I was able to transcribe it after-the-fact using OCR. AI fighting AI.
3. There is a (vanishingly small) chance that this was a legitimate offer. The con was sophisticated. The opportunity was AI researcher catnip, and the chatbot used a voice clip, data from legitimate operations, strong and meta discussion points, roundabout asks for forbidden questions, lots of ego stroking, an assumptive close, and a weak honeypot to try to pull me in. The experience supports my contention that fraud is one of the three killer apps for generative AI.

The folder includes a transcript of my conversation with Amy; reformatted from Signal bubbles; minimal redactions, for security / privacy. There's also a redacted transcript of my email thread with the company's recruiting department, and a screen shot of the LinkedIn hand-off message from Amy's assistant.

Amy demonstrated a command of AI technical and ethical issues than I'd expect from a "Chief People Officer." Honestly, my conversation with Amy was one of the most enjoyable and thought-provoking I've ever had about AI. Was Amy just a chat bot, or was there a human in the loop?  Who, or what, do you think "Amy" was?
