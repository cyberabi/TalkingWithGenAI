# Talking With Generative AI

The subfolders of this repo capture human-AI interactions that I found to have interesting results or implications.

## brontes

I prompted ChatGPT to write a one-page essay comparing and contrasting Jane Eyre and Wuthering Heights. Then, in a different session, I prompted ChatGPT to critique the essay that it had generated. Both results were interesting! And I have three personal takeaways from this experiment.

1. Both the essay, and the critique, are of good quality and no more wrong than an English Lit student would be. Humans have analyzed and compared these two novels for 150 years; the LLM had plenty of source material to draw from and the results meet my expectation.
2. That ChatGPT can critique its own essay as "overly broad," "overly stark," "reductive," "overstated," "broadly true, but..." and "missing acknowledgment" reflects the biases and constraints of the prompts, but also serves as a warning as to quality of results when using the LLM naively. If the LLM can pick this essay apart, so can your English teacher.
3. Some educators have suggested that asking students to critique an essay written by ChatGPT could reduce classroom cheating. I feel this example illustrates that a student could simply ask ChatGPT to critique the essay, again cheating. They'd probably need to qualify the prompt of the critique to write it in essay form, and to use only 10th grade vocabulary, to pass; but: feasibility of this cheat proved.

The folder includes the prompts I used, and the output of the LLM.

